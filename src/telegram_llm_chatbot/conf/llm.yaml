custom:
  _target_: telegram_llm_chatbot.api.schemas.ModelConfig
  chat_history_limit: 10
  max_tokens: 2500
  model_name: gpt-4o-mini
  provider: openai
  stream: false
  temperature: 0.7
fireworksai_llama:
  _target_: telegram_llm_chatbot.api.schemas.ModelConfig
  chat_history_limit: 10
  max_tokens: 2500
  model_name: accounts/fireworks/models/llama-v3-70b-instruct
  provider: fireworksai
  stream: true
  temperature: 0.7
openai_gpt4o:
  _target_: telegram_llm_chatbot.api.schemas.ModelConfig
  chat_history_limit: 10
  max_tokens: 3000
  model_name: gpt-4o-mini
  provider: openai
  stream: true
  temperature: 0.7
